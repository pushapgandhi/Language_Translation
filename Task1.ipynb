{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwPL0hIlGKoA"
   },
   "source": [
    "# <font color='red'>**Sequence to sequence implementation**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nYHE_1ck2az"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_check_encoder(), grader_check_attention(), grader_onestepdecoder() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**\n",
    "\n",
    "**Note 1:**  There are many blogs on the attention mechanisum which might be misleading you,\n",
    " so do read the references completly and after that only please check the internet.\n",
    " The best things is to read the research papers and try to implement it on your own. \n",
    "\n",
    "**Note 2:** To complete this assignment, the reference that are mentioned will be enough.\n",
    "\n",
    "**Note 3:** If you are starting this assignment, you might have completed minimum of 20 assignment.\n",
    " If  you are still not able to implement this algorithm you might have rushed in the previous assignments \n",
    "with out learning much and didn't spend your time productively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyfZo8fmLOec"
   },
   "source": [
    "## Task -1: Simple Encoder and Decoder\n",
    "Implement simple Encoder-Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21562,
     "status": "ok",
     "timestamp": 1623166493432,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "_mO2hhj8tRC-",
    "outputId": "ad212a1e-2d0a-4548-dac2-1484cf9fda13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvNSZXNkkOkO"
   },
   "source": [
    "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
    "\n",
    "2. You will find **ita.txt** file in that ZIP, \n",
    "you can read that data using python and preprocess that data this way only: \n",
    "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
    "    \n",
    "3. You have to implement a simple Encoder and Decoder architecture  \n",
    "\n",
    "4. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
    "\n",
    "5. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
    "\n",
    "6.  a. Check the reference notebook <br>\n",
    "    b. <a href=\"https://medium.com/analytics-vidhya/understand-sequence-to-sequence-models-in-a-more-intuitive-way-1d517d8795bb\">Resource 2</a>\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k_AlAuKJqVA"
   },
   "source": [
    "<font color='blue'>**Load the data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2017,
     "status": "ok",
     "timestamp": 1623166506314,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "liQRfifztEu6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "executionInfo": {
     "elapsed": 2651,
     "status": "ok",
     "timestamp": 1623166508939,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "fU80Ao-AGaob",
    "outputId": "cd02fb68-ade1-4b24-ebd2-6d4a2239336f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corri!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corra!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Correte!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Chi?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345239</th>\n",
       "      <td>If you want to sound like a native speaker, yo...</td>\n",
       "      <td>Se vuoi sembrare un madrelingua, devi essere d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345240</th>\n",
       "      <td>If you want to sound like a native speaker, yo...</td>\n",
       "      <td>Se vuoi sembrare un madrelingua, devi essere d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345241</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Se qualcuno che non conosce il tuo background ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345242</th>\n",
       "      <td>Doubtless there exists in this world precisely...</td>\n",
       "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345243</th>\n",
       "      <td>Doubtless there exists in this world precisely...</td>\n",
       "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345244 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  english                                            italian\n",
       "0                                                     Hi.                                              Ciao!\n",
       "1                                                    Run!                                             Corri!\n",
       "2                                                    Run!                                             Corra!\n",
       "3                                                    Run!                                           Correte!\n",
       "4                                                    Who?                                               Chi?\n",
       "...                                                   ...                                                ...\n",
       "345239  If you want to sound like a native speaker, yo...  Se vuoi sembrare un madrelingua, devi essere d...\n",
       "345240  If you want to sound like a native speaker, yo...  Se vuoi sembrare un madrelingua, devi essere d...\n",
       "345241  If someone who doesn't know your background sa...  Se qualcuno che non conosce il tuo background ...\n",
       "345242  Doubtless there exists in this world precisely...  Senza dubbio esiste in questo mondo proprio la...\n",
       "345243  Doubtless there exists in this world precisely...  Senza dubbio esiste in questo mondo proprio la...\n",
       "\n",
       "[345244 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ass-28/ita.txt', delimiter = \"\\t\",names = [\"english\",\"italian\",\"z\"]).drop(\"z\",axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmGWTdRmKRph"
   },
   "source": [
    "<font color='blue'>**Preprocess data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1623166509962,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "bsRKcU3xtEu-"
   },
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    '''This function returns the decontracted words for English Language'''\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "def preprocessor(text):\n",
    "    '''This function returns preprocessed data for English Language'''\n",
    "    text = text.lower()\n",
    "    text = decontracted(text)\n",
    "    text = re.sub(\"[^A-Za-z0-9 ]+\",'',text)\n",
    "    return text\n",
    "\n",
    "def preprocessor_ita(text):\n",
    "    '''This function returns preprocessed data for Italian Language'''\n",
    "    text = text.lower()\n",
    "    text = decontracted(text)\n",
    "    text = re.sub(\"[^A-Za-z0-9 ]+\",'',text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "executionInfo": {
     "elapsed": 7737,
     "status": "ok",
     "timestamp": 1623166518332,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "eLLsIkJ8tEvA",
    "outputId": "246cf65a-a5ad-4b57-d405-2be1debd44c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>ciao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run</td>\n",
       "      <td>corri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>corra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run</td>\n",
       "      <td>correte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who</td>\n",
       "      <td>chi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345239</th>\n",
       "      <td>if you want to sound like a native speaker you...</td>\n",
       "      <td>se vuoi sembrare un madrelingua devi essere di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345240</th>\n",
       "      <td>if you want to sound like a native speaker you...</td>\n",
       "      <td>se vuoi sembrare un madrelingua devi essere di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345241</th>\n",
       "      <td>if someone who does not know your background s...</td>\n",
       "      <td>se qualcuno che non conosce il tuo background ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345242</th>\n",
       "      <td>doubtless there exists in this world precisely...</td>\n",
       "      <td>senza dubbio esiste in questo mondo proprio la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345243</th>\n",
       "      <td>doubtless there exists in this world precisely...</td>\n",
       "      <td>senza dubbio esiste in questo mondo proprio la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345244 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  english                                            italian\n",
       "0                                                      hi                                               ciao\n",
       "1                                                     run                                              corri\n",
       "2                                                     run                                              corra\n",
       "3                                                     run                                            correte\n",
       "4                                                     who                                                chi\n",
       "...                                                   ...                                                ...\n",
       "345239  if you want to sound like a native speaker you...  se vuoi sembrare un madrelingua devi essere di...\n",
       "345240  if you want to sound like a native speaker you...  se vuoi sembrare un madrelingua devi essere di...\n",
       "345241  if someone who does not know your background s...  se qualcuno che non conosce il tuo background ...\n",
       "345242  doubtless there exists in this world precisely...  senza dubbio esiste in questo mondo proprio la...\n",
       "345243  doubtless there exists in this world precisely...  senza dubbio esiste in questo mondo proprio la...\n",
       "\n",
       "[345244 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREPROCESSED DATA INTO A DATAFRAME\n",
    "df[\"english\"] = df.english.apply(preprocessor)\n",
    "df[\"italian\"] = df.italian.apply(preprocessor_ita)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "executionInfo": {
     "elapsed": 979,
     "status": "ok",
     "timestamp": 1623166519289,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "UvJDuMRCtEvC",
    "outputId": "2af7b545-b03b-431a-d7f7-32867222d488"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ciao</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corri</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>corra</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>correte</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chi</td>\n",
       "      <td>&lt;start&gt; who</td>\n",
       "      <td>who &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344915</th>\n",
       "      <td>charles moore cre il forth nel tentativo di au...</td>\n",
       "      <td>&lt;start&gt; charles moore created forth in an atte...</td>\n",
       "      <td>charles moore created forth in an attempt to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344998</th>\n",
       "      <td>se la tua azienda opera principalmente con lam...</td>\n",
       "      <td>&lt;start&gt; if your company primarily does busines...</td>\n",
       "      <td>if your company primarily does business with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344999</th>\n",
       "      <td>se la sua azienda opera principalmente con lam...</td>\n",
       "      <td>&lt;start&gt; if your company primarily does busines...</td>\n",
       "      <td>if your company primarily does business with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345000</th>\n",
       "      <td>se la vostra azienda opera principalmente con ...</td>\n",
       "      <td>&lt;start&gt; if your company primarily does busines...</td>\n",
       "      <td>if your company primarily does business with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345001</th>\n",
       "      <td>lintelligenza  fondata nella capacit di ricono...</td>\n",
       "      <td>&lt;start&gt; intelligence is found in the capacity ...</td>\n",
       "      <td>intelligence is found in the capacity to recog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344860 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  italian  ...                                        english_out\n",
       "0                                                    ciao  ...                                           hi <end>\n",
       "1                                                   corri  ...                                          run <end>\n",
       "2                                                   corra  ...                                          run <end>\n",
       "3                                                 correte  ...                                          run <end>\n",
       "4                                                     chi  ...                                          who <end>\n",
       "...                                                   ...  ...                                                ...\n",
       "344915  charles moore cre il forth nel tentativo di au...  ...  charles moore created forth in an attempt to i...\n",
       "344998  se la tua azienda opera principalmente con lam...  ...  if your company primarily does business with a...\n",
       "344999  se la sua azienda opera principalmente con lam...  ...  if your company primarily does business with a...\n",
       "345000  se la vostra azienda opera principalmente con ...  ...  if your company primarily does business with a...\n",
       "345001  lintelligenza  fondata nella capacit di ricono...  ...  intelligence is found in the capacity to recog...\n",
       "\n",
       "[344860 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REMOVING SENTENCES WITH MAXIMUM LENGTH GREATER THAN 20\n",
    "df[\"eng_len\"] = df.english.apply(lambda x: len(x.split()))\n",
    "df = df[df.eng_len<=20]\n",
    "df[\"ita_len\"] = df.italian.apply(lambda x: len(x.split()))\n",
    "df  = df[df.ita_len<=20]\n",
    "\n",
    "# ADDING <start> TO THE BEGINING OF ENGLISH SENTENCES\n",
    "df[\"english_inp\"]= \"<start> \"+ df.english\n",
    "# ADDING <end> TO THE END IN ENGLISH SENTENCES\n",
    "df[\"english_out\"]= df.english+ \" <end>\"\n",
    "df.drop([\"english\",\"eng_len\",\"ita_len\"],axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btcBJyAqtEvD"
   },
   "source": [
    "# Train_Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1623166519293,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "79Pq93dftEvD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1623166519762,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "T2Pv49RQtEvE"
   },
   "outputs": [],
   "source": [
    "train , validation = train_test_split(df,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1623166519769,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "hISIxE3OtEvF"
   },
   "outputs": [],
   "source": [
    "# ADDING <end> TO THE END OF FIRST ENGLISH SENTENCE IN \"english_inp\"\n",
    "train.iloc[0][\"english_inp\"]  = train.iloc[0][\"english_inp\"] + \" <end>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1623166519771,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "TFfHY9NJtEvF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LP1oFVI7tEvG"
   },
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1623166519773,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "AV8ZqosvtEvG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2540,
     "status": "ok",
     "timestamp": 1623166522287,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "7kqy0T77tEvH"
   },
   "outputs": [],
   "source": [
    "# TOKENIZING ENGLISH SENTENCES\n",
    "tk_eng = Tokenizer(filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tk_eng.fit_on_texts(train.english_inp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2797,
     "status": "ok",
     "timestamp": 1623166525040,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "Q8rPJDdUtEvH"
   },
   "outputs": [],
   "source": [
    "# TOKENIZING ITALIAN SENTENCES\n",
    "tk_ita = Tokenizer()\n",
    "tk_ita.fit_on_texts(train.italian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1623166525043,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "9QqElB_nKZos"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8RDrP4xKabR"
   },
   "source": [
    "## <font color='blue'>**Implement custom encoder decoder**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A45uc0JILMlV"
   },
   "source": [
    "<font color='blue'>**Encoder**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1623166528822,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "QDmVVr57tEvJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1623166529483,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "ZWnp2FsRtEvJ"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "    '''\n",
    "    def __init__(self , vocab_size , embedding_dim , enc_units , input_len):\n",
    "        super().__init__()\n",
    "        \n",
    "        # STATING ALL THE VARIABLES\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_len = input_len\n",
    "        self.enc_units = enc_units\n",
    "        self.enc_output = 0\n",
    "        self.state_h = 0\n",
    "        self.state_c=0\n",
    "        # INITALIZING EMBEDDING LAYER\n",
    "        self.embedding = layers.Embedding(input_dim= self.vocab_size,\n",
    "                                         output_dim = self.embedding_dim,\n",
    "                                         mask_zero = True,\n",
    "                                          input_length = self.input_len\n",
    "                                         )\n",
    "        # INTIALIZING LSTM LAYER\n",
    "        self.lstm = layers.LSTM(units= self.enc_units,return_state = True,return_sequences=True )\n",
    "        \n",
    "    def call(self,input,state):\n",
    "        '''\n",
    "          This function takes a sequence input and the initial states of the encoder.\n",
    "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "          returns -- encoder_output, last time step's hidden and cell state\n",
    "        '''\n",
    "        # CONVERTING INPUT TO EMBEDDED VECTORS\n",
    "        emb = self.embedding(input)\n",
    "        # PASSING THROUGH LSTM LAYER\n",
    "        self.enc_output , self.state_h , self.state_c = self.lstm(emb,initial_state=state)\n",
    "        \n",
    "        return self.enc_output , self.state_h , self.state_c \n",
    "    \n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "        '''\n",
    "      Given a batch size it will return intial hidden state and intial cell state.\n",
    "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "      '''\n",
    "        # INITIALIZING THE VALUES OF H AND C STATES FOR LSTM\n",
    "        initial_h = tf.zeros(shape=(batch_size,self.enc_units))\n",
    "        initial_c = tf.zeros(shape=(batch_size,self.enc_units))\n",
    "        return [initial_h , initial_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtbOI3VwLOe0"
   },
   "source": [
    "<font color='orange'>**Grader function - 1**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8313,
     "status": "ok",
     "timestamp": 1623166538668,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "ziSqOgmhLOe1",
    "outputId": "e1fa6812-d93f-4c59-ea8e-d7492b78bb28",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_check_encoder():\n",
    "    '''\n",
    "        vocab-size: Unique words of the input language,\n",
    "        embedding_size: output embedding dimension for each word after embedding layer,\n",
    "        lstm_size: Number of lstm units,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "    '''\n",
    "    vocab_size=10\n",
    "    embedding_size=20\n",
    "    lstm_size=32\n",
    "    input_length=10\n",
    "    batch_size=16\n",
    "    #Intialzing encoder \n",
    "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
    "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
    "    #Intializing encoder initial states\n",
    "    initial_state=encoder.initialize_states(batch_size)\n",
    "    \n",
    "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
    "    \n",
    "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
    "    return True\n",
    "print(grader_check_encoder())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1623166538670,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "9ucs27cKtEvN"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,vocab_size , embedding_dim, dec_unit,input_len ):\n",
    "        super().__init__()\n",
    "        # INITALIZING ALL THE VARIABLES \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_len = input_len\n",
    "        self.dec_unit =dec_unit\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        \n",
    "        # INITALIZING EMBEDDING AND LSTM LAYER\n",
    "        self.embedding = layers.Embedding(input_dim = self.vocab_size,\n",
    "                                          output_dim = self.embedding_dim,\n",
    "                                         mask_zero=True,\n",
    "                                         input_length = self.input_len)\n",
    "        self.lstm = layers.LSTM(units = self.dec_unit,\n",
    "                               return_sequences=True,\n",
    "                               return_state=True)\n",
    "        \n",
    "    def call(self,input, state):\n",
    "        # FORMING THE EMBEDDED VECTORS\n",
    "        emb = self.embedding(input)\n",
    "        \n",
    "        # LSTM OUTPUT\n",
    "        dec_out,state_h,state_c = self.lstm(emb,initial_state = state)\n",
    "        \n",
    "        return dec_out,state_h,state_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hq-I0SUbLOe8"
   },
   "source": [
    "<font color='orange'>**Grader function - 2**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1623166538672,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "0B0gokgKLOe8",
    "outputId": "b4a9dedd-c757-49a8-e63a-e036af2fe3a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def grader_decoder():\n",
    "    '''\n",
    "        out_vocab_size: Unique words of the target language,\n",
    "        embedding_size: output embedding dimension for each word after embedding layer,\n",
    "        dec_units: Number of lstm units in decoder,\n",
    "        input_length: Length of the input sentence,\n",
    "        batch_size\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    out_vocab_size=13 \n",
    "    embedding_dim=12 \n",
    "    input_length=10\n",
    "    dec_units=16 \n",
    "    batch_size=32\n",
    "    \n",
    "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
    "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
    "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
    "    states=[state_h,state_c]\n",
    "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
    "    output,_,_=decoder(target_sentences, states)\n",
    "    assert(output.shape==(batch_size,input_length,dec_units))\n",
    "    return True\n",
    "print(grader_decoder())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODER_DECODER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1623166538673,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "BXrIj4scLOe_"
   },
   "outputs": [],
   "source": [
    "class Encoder_decoder(tf.keras.Model):\n",
    "    '''\n",
    "    ARGUMENTS:\n",
    "    enc_vocab_size,\n",
    "    enc_emb_dim,\n",
    "    enc_units,\n",
    "    enc_input_length,\n",
    "    dec_vocab_size,\n",
    "    dec_emb_dim,\n",
    "    dec_units,\n",
    "    dec_input_length,\n",
    "    batch_size'''\n",
    "    def __init__(self,enc_vocab_size,enc_emb_dim,enc_units,enc_input_length,dec_vocab_size,dec_emb_dim,dec_units,dec_input_length,batch_size):\n",
    "        super().__init__()\n",
    "        # INITIALIZING ALL REQUIRED VARIABLES\n",
    "        # BATCH SIZE\n",
    "        self.batch_size = batch_size\n",
    "        # ENCODER MODEL\n",
    "        self.encoder = Encoder(vocab_size= enc_vocab_size , embedding_dim= enc_emb_dim ,\n",
    "                               enc_units=enc_units ,input_len=enc_input_length)\n",
    "        # DECODER MODEL\n",
    "        self.decoder = Decoder(vocab_size = dec_vocab_size  , embedding_dim = dec_emb_dim ,\n",
    "                               dec_unit=dec_units ,input_len=dec_input_length)\n",
    "        # DENSE LAYER\n",
    "        self.dense = layers.Dense(dec_vocab_size,activation = \"softmax\")\n",
    "    \n",
    "    def call(self,data):\n",
    "        '''\n",
    "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
    "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
    "        C. Pass the decoder_outputs into Dense layer \n",
    "        \n",
    "        Return decoder_outputs\n",
    "        '''\n",
    "        # GETTING THE INPUT FOR ENCODER AND DECODER\n",
    "        input,output  = data[0],data[1]\n",
    "        \n",
    "        # INITIAL STATES FOR ENCODER METHOD\n",
    "        initial_states = self.encoder.initialize_states(self.batch_size)\n",
    "        # PASSING THE INPUT AND INTIAL STATES TO ENCODER \n",
    "        enc_output,state_h,state_c = self.encoder(input,initial_states)\n",
    "        \n",
    "        enc_states = [state_h,state_c]\n",
    "        # PASSING DECODER INPUT AND ENDOER OUTPUT STATES TO DECODER\n",
    "        dec_output,_,_ = self.decoder(output,enc_states)\n",
    "        # PASSING DECODER OUTPUT TO DENSE LATER\n",
    "        dense_output = self.dense(dec_output)\n",
    "        \n",
    "        # RETURNING DENSE OUTPUT\n",
    "        return dense_output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d9x-0FhtEvU"
   },
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1623166538675,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "FzXQfExWtEvU"
   },
   "outputs": [],
   "source": [
    "from  tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1623166542691,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "kUUPWULstEvV"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Dataset :\n",
    "    def __init__(self, data,tk_eng,tk_ita,max_len):\n",
    "        self.encoder_inp = data[\"italian\"].values\n",
    "        self.decoder_inp = data[\"english_inp\"].values\n",
    "        self.decoder_out = data[\"english_out\"].values\n",
    "        self.tk_eng = tk_eng\n",
    "        self.tk_ita = tk_ita\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        # ITALIAN TO INTEGER SEQUENCES\n",
    "        self.encoder_seq = self.tk_ita.texts_to_sequences([self.encoder_inp[i]])\n",
    "        # ENGLISH TO INTEGER SEQUENCES \n",
    "        self.decoder_inp_seq = self.tk_eng.texts_to_sequences([self.decoder_inp[i]])\n",
    "        # ENGLISH TO INTEGER SEQUENCES\n",
    "        self.decoder_out_seq = self.tk_eng.texts_to_sequences([self.decoder_out[i]])\n",
    "        \n",
    "        # PADDING THE ENCODER INPUT SEQUENCES\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq,maxlen = self.max_len,padding=\"post\")\n",
    "        # PADDING THE DECODER INPUT SEQUENCES\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq,maxlen = self.max_len,padding = \"post\")\n",
    "        # PADDING DECODER OUTPUT SEQUENCES\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq,maxlen = self.max_len,padding = \"post\")\n",
    "        return self.encoder_seq ,  self.decoder_inp_seq,  self.decoder_out_seq\n",
    "    \n",
    "    def __len__(self):\n",
    "        # RETURN THE LEN OF INPUT ENDODER\n",
    "        return len(self.encoder_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1623166547464,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "oh6HjdPGtEvV"
   },
   "outputs": [],
   "source": [
    "class Dataloader(tf.keras.utils.Sequence):\n",
    "    def __init__(self,batch_size,dataset):\n",
    "        # INTIALIZING THE REQUIRED VARIABLES \n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.totl_points = self.dataset.encoder_inp.shape[0]\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        # STATING THE START AND STOP VATIABLE CONTAINGING INDEX VALUES FOR EACH BATCH\n",
    "        start = i * self.batch_size\n",
    "        stop = (i+1)*self.batch_size\n",
    "        \n",
    "        # PLACEHOLDERS FOR BATCHED DATA\n",
    "        batch_ita =[]\n",
    "        batch_eng_input = []\n",
    "        batch_eng_out =[]\n",
    "\n",
    "        for j in range(start,stop): # FOR EACH VALUE IN START TO STOP \n",
    "            \n",
    "            a,b,c = self.dataset[j] # DATASET RETURNS ITALIAN , ENGLIGH_INPUT, ENGLISH_OUTPUT\n",
    "            batch_ita.append(a[0]) # APPENDING ITALIAN TO batch_ita\n",
    "            batch_eng_input.append(b[0]) # APPENGIND ENGLISH INPUT TO batch_eng_input\n",
    "            batch_eng_out.append(c[0]) # APPENDING ENGLISH OUTPUT TO batch_eng_out\n",
    "        \n",
    "        # Conveting list to array   \n",
    "        batch_ita = (np.array(batch_ita)) \n",
    "        batch_eng_input = np.array(batch_eng_input)\n",
    "        batch_eng_out = np.array(batch_eng_out)\n",
    "        \n",
    "        return [batch_ita , batch_eng_input],batch_eng_out\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Returning the number of batches\n",
    "        return int(self.totl_points/self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1623166552375,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "7KR0eQS1tEvW"
   },
   "outputs": [],
   "source": [
    "# FORMING OBJECTS OF DATASET AND DATALOADER FOR TRAIN DATASET\n",
    "train_dataset = Dataset(train,tk_eng,tk_ita,20)\n",
    "train_dataloader = Dataloader( batch_size = 1024 , dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1623166553373,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "zeG3SgLwtEvX"
   },
   "outputs": [],
   "source": [
    "# FORMING OBJECTS OF DATASET AND DATALOADER FOR TEST DATASET\n",
    "val_dataset = Dataset(validation,tk_eng,tk_ita,20)\n",
    "val_dataloader = Dataloader(batch_size=1024,dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4370752,
     "status": "ok",
     "timestamp": 1623170931559,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "AzOMd-pStEvX",
    "outputId": "1773293d-8219-4516-f0c7-80898a64feee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "269/269 [==============================] - 90s 317ms/step - loss: 1.8412 - val_loss: 1.6170\n",
      "Epoch 2/50\n",
      "269/269 [==============================] - 84s 311ms/step - loss: 1.4966 - val_loss: 1.3763\n",
      "Epoch 3/50\n",
      "269/269 [==============================] - 84s 313ms/step - loss: 1.2919 - val_loss: 1.2158\n",
      "Epoch 4/50\n",
      "269/269 [==============================] - 84s 312ms/step - loss: 1.1505 - val_loss: 1.0903\n",
      "Epoch 5/50\n",
      "269/269 [==============================] - 84s 312ms/step - loss: 1.0268 - val_loss: 0.9782\n",
      "Epoch 6/50\n",
      "269/269 [==============================] - 84s 314ms/step - loss: 0.9178 - val_loss: 0.8847\n",
      "Epoch 7/50\n",
      "269/269 [==============================] - 84s 312ms/step - loss: 0.8277 - val_loss: 0.8086\n",
      "Epoch 8/50\n",
      "269/269 [==============================] - 85s 314ms/step - loss: 0.7519 - val_loss: 0.7421\n",
      "Epoch 9/50\n",
      "269/269 [==============================] - 85s 315ms/step - loss: 0.6839 - val_loss: 0.6859\n",
      "Epoch 10/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.6226 - val_loss: 0.6316\n",
      "Epoch 11/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.5659 - val_loss: 0.5839\n",
      "Epoch 12/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.5148 - val_loss: 0.5436\n",
      "Epoch 13/50\n",
      "269/269 [==============================] - 85s 315ms/step - loss: 0.4676 - val_loss: 0.5023\n",
      "Epoch 14/50\n",
      "269/269 [==============================] - 85s 315ms/step - loss: 0.4255 - val_loss: 0.4684\n",
      "Epoch 15/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.3879 - val_loss: 0.4381\n",
      "Epoch 16/50\n",
      "269/269 [==============================] - 85s 315ms/step - loss: 0.3538 - val_loss: 0.4122\n",
      "Epoch 17/50\n",
      "269/269 [==============================] - 85s 315ms/step - loss: 0.3241 - val_loss: 0.3885\n",
      "Epoch 18/50\n",
      "269/269 [==============================] - 85s 315ms/step - loss: 0.2980 - val_loss: 0.3699\n",
      "Epoch 19/50\n",
      "269/269 [==============================] - 85s 315ms/step - loss: 0.2746 - val_loss: 0.3509\n",
      "Epoch 20/50\n",
      "269/269 [==============================] - 85s 315ms/step - loss: 0.2542 - val_loss: 0.3362\n",
      "Epoch 21/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.2361 - val_loss: 0.3239\n",
      "Epoch 22/50\n",
      "269/269 [==============================] - 85s 314ms/step - loss: 0.2197 - val_loss: 0.3131\n",
      "Epoch 23/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.2052 - val_loss: 0.3019\n",
      "Epoch 24/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.1924 - val_loss: 0.2933\n",
      "Epoch 25/50\n",
      "269/269 [==============================] - 85s 315ms/step - loss: 0.1809 - val_loss: 0.2861\n",
      "Epoch 26/50\n",
      "269/269 [==============================] - 85s 315ms/step - loss: 0.1704 - val_loss: 0.2792\n",
      "Epoch 27/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.1606 - val_loss: 0.2732\n",
      "Epoch 28/50\n",
      "269/269 [==============================] - 85s 315ms/step - loss: 0.1518 - val_loss: 0.2678\n",
      "Epoch 29/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.1436 - val_loss: 0.2634\n",
      "Epoch 30/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.1362 - val_loss: 0.2585\n",
      "Epoch 31/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.1296 - val_loss: 0.2553\n",
      "Epoch 32/50\n",
      "269/269 [==============================] - 85s 317ms/step - loss: 0.1233 - val_loss: 0.2520\n",
      "Epoch 33/50\n",
      "269/269 [==============================] - 85s 317ms/step - loss: 0.1181 - val_loss: 0.2488\n",
      "Epoch 34/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.1119 - val_loss: 0.2468\n",
      "Epoch 35/50\n",
      "269/269 [==============================] - 85s 317ms/step - loss: 0.1071 - val_loss: 0.2443\n",
      "Epoch 36/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.1023 - val_loss: 0.2414\n",
      "Epoch 37/50\n",
      "269/269 [==============================] - 85s 317ms/step - loss: 0.0977 - val_loss: 0.2390\n",
      "Epoch 38/50\n",
      "269/269 [==============================] - 85s 317ms/step - loss: 0.0934 - val_loss: 0.2386\n",
      "Epoch 39/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.0895 - val_loss: 0.2372\n",
      "Epoch 40/50\n",
      "269/269 [==============================] - 85s 317ms/step - loss: 0.0860 - val_loss: 0.2362\n",
      "Epoch 41/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.0825 - val_loss: 0.2358\n",
      "Epoch 42/50\n",
      "269/269 [==============================] - 85s 317ms/step - loss: 0.0791 - val_loss: 0.2347\n",
      "Epoch 43/50\n",
      "269/269 [==============================] - 85s 317ms/step - loss: 0.0763 - val_loss: 0.2334\n",
      "Epoch 44/50\n",
      "269/269 [==============================] - 85s 317ms/step - loss: 0.0730 - val_loss: 0.2336\n",
      "Epoch 45/50\n",
      "269/269 [==============================] - 85s 317ms/step - loss: 0.0701 - val_loss: 0.2328\n",
      "Epoch 46/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.0674 - val_loss: 0.2325\n",
      "Epoch 47/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.0654 - val_loss: 0.2319\n",
      "Epoch 48/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.0627 - val_loss: 0.2332\n",
      "Epoch 49/50\n",
      "269/269 [==============================] - 85s 316ms/step - loss: 0.0605 - val_loss: 0.2320\n",
      "Epoch 50/50\n",
      "269/269 [==============================] - 86s 319ms/step - loss: 0.0582 - val_loss: 0.2328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f148889a2d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING THE MODEL FOR 50 EPOCHS\n",
    "model1 = Encoder_decoder(enc_vocab_size=len(tk_ita.word_index)+1,\n",
    "                         enc_emb_dim = 50,\n",
    "                         enc_units=256,enc_input_length=20,\n",
    "                         dec_vocab_size =len(tk_eng.word_index)+1,\n",
    "                         dec_emb_dim =100,\n",
    "                         dec_units=256,\n",
    "                         dec_input_length = 20,\n",
    "                         batch_size=1024)\n",
    "\n",
    "train_steps = train_dataloader.__len__()\n",
    "val_steps  = val_dataloader.__len__()\n",
    "\n",
    "model1.compile(optimizer=\"adam\",loss='sparse_categorical_crossentropy')\n",
    "model1.fit(train_dataloader,steps_per_epoch=train_steps,epochs=50,validation_data = val_dataloader,validation_steps =val_steps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1623170991521,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "3f_-JbFYtEva"
   },
   "outputs": [],
   "source": [
    "def predict(ita_text,model):\n",
    "    '''This function inputs the datapoint and return the predicted translated output'''\n",
    "    # forming integer sequences\n",
    "    seq = tk_ita.texts_to_sequences([ita_text])\n",
    "    # padding the sequences\n",
    "    seq = pad_sequences(seq,maxlen = 20 , padding=\"post\")\n",
    "    # initializing the states for states of lstms\n",
    "    state = model.layers[0].initialize_states(1)\n",
    "    # generating the output from encoder\n",
    "    enc_output,state_h,state_c= model.layers[0](seq,state)\n",
    "    \n",
    "    # placeholder for predicted output\n",
    "    pred = []\n",
    "    \n",
    "    input_state = [state_h,state_c]\n",
    "    # initailizing the vector for inputing to decoder\n",
    "    current_vec = tf.ones((1,1))\n",
    "    \n",
    "    for i in range(20): # for each word in the input\n",
    "        # passing each word through decoder layer\n",
    "        dec_output,dec_state_h,dec_state_c = model.layers[1](current_vec , input_state)\n",
    "        # passing decoder output through dense  layer\n",
    "        dense = model.layers[2](dec_output)\n",
    "        # taking argmax and getting the word index and updating the current vector\n",
    "        current_vec = np.argmax(dense ,axis = -1)\n",
    "        # updating the decoder states\n",
    "        input_state = [dec_state_h,dec_state_c]\n",
    "        # getting the actual word from the vocab\n",
    "        pred.append(tk_eng.index_word[current_vec[0][0]])\n",
    "        \n",
    "        # if the actual word is <end> break the loop\n",
    "        if tk_eng.index_word[current_vec[0][0]]==\"<end>\":\n",
    "            break\n",
    "        \n",
    "    return \" \".join(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 1650,
     "status": "ok",
     "timestamp": 1623170997081,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "xGODy-wTtEvc"
   },
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLUE SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42795,
     "status": "ok",
     "timestamp": 1623171041706,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "YSv_SLUWtEvc",
    "outputId": "3ddc340e-dbb1-4ace-94d0-ed266a4ff221"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:42, 23.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8380497994495004"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GETTING THE AVG BELU SCORE AFTER PREDICTING 1000 RANDOM SENTENCES\n",
    "BLEU = []\n",
    "\n",
    "test_data = validation.loc[np.random.choice(validation.index,size = 1000)][[\"italian\",\"english_out\"]]\n",
    "for ind,i in tqdm(test_data.iterrows(),position=0):\n",
    "    pred = predict(i.italian,model1)\n",
    "    act = i.english_out\n",
    "    b =bleu.sentence_bleu(act,pred)\n",
    "    BLEU.append(b)\n",
    "\n",
    "np.mean(BLEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1623171041717,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "Tuk5LYTytEvd",
    "outputId": "191607b8-b16c-4dac-c8f3-3e3da9f717e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU SCORE 0.8380497994495004\n"
     ]
    }
   ],
   "source": [
    "print(\"BLEU SCORE\",np.mean(BLEU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PRDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1623171720594,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "bpH-Ndi7ihSg",
    "outputId": "7eddbcbc-ee77-4ed3-f598-7db79ef1746e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted==> i have got to get to book before this month <end>\n",
      "Actual==> i have to finish reading that book by tomorrow <end>\n"
     ]
    }
   ],
   "source": [
    "random = np.random.randint(0,2000,1)[0]\n",
    "print(\"Predicted==>\",predict( validation.italian.values[random] , model1))\n",
    "print(\"Actual==>\",validation.english_out.values[random])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1623171721055,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "JaYR2_zAig-t",
    "outputId": "e754210f-b909-42e7-e9a6-b1b8518717c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted==> i am learning english to boston by road <end>\n",
      "Actual==> i am learning english with the idea of going to america <end>\n"
     ]
    }
   ],
   "source": [
    "random = np.random.randint(0,2000,1)[0]\n",
    "print(\"Predicted==>\",predict( validation.italian.values[random] , model1))\n",
    "print(\"Actual==>\",validation.english_out.values[random])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1623171721057,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "Ff1lV0ITM6_p",
    "outputId": "9b4f87e7-fd42-48d9-b9f0-3bf491f4e0c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted==> tom is anxious to leave <end>\n",
      "Actual==> tom is anxious to leave <end>\n"
     ]
    }
   ],
   "source": [
    "random = np.random.randint(0,2000,1)[0]\n",
    "print(\"Predicted==>\",predict( validation.italian.values[random] , model1))\n",
    "print(\"Actual==>\",validation.english_out.values[random])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9xrhI_nktH4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
